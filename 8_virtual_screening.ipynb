{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual Screening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perform virtual screening against PubChem using ligand-based approach\n",
    "- Apply filters to prioritize virtual screening hit list.\n",
    "- Learn how to use pandas' data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we perform virtual screening against PubChem using a set of known ligands for muscle glycogen phosphorylase.  Compound filters will be applied to identify drug-like compounds and unique structures in terms of canonical SMILES will be selected to remove redundant structures.  In a second, optional assignment the binding mode will be predicted using molecular docking for some top-ranked compounds in the list. This assignement requires installing multiple software packages and is not always easy for that reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read known ligands from a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a starting point, let's download a set of known ligands against muscle glycogen phosphorylase.  From Canvas download the pygm_1c8k_actives.ism file. These data are obtained from the DUD-E (Directory of Useful Decoys, Enhanced) data sets (http://dude.docking.org/), which contain known actives and inactives for 102 protein targets.  The DUD-E sets are widely used in benchmarking studies that compare the performance of different virtual screening approaches (https://doi.org/10.1021/jm300687e)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the pygm_1c8k_actives.ism file was generated: Go to the DUD-E target page (http://dude.docking.org/targets) and find muscle glycogen phosphorylase (Target Name: PYGM, PDB ID: 1c8k) from the target list.  Clicking the target name \"PYGM\" directs you to the page that lists various files (http://dude.docking.org/targets/pygm).  Download file \"**actives_final.ism**\", which contains the SMILES strings of known actives.  Rename the file name as \"**pygm_1c8k_actives.ism**\".  \\[Open the file in WordPad or other text viewer/editor to check the format of this file\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read the data from the file using the pandas library (https://pandas.pydata.org/).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['smiles','dat', 'id']\n",
    "df_act = pd.read_csv(os.path.join(\"data\", \"pygm_1c8k_actives.ism\"), sep=\" \", names=colnames)\n",
    "df_act.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_act))    # Show how many structures are in the \"data frame\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's speed things up by taking only the top 20 from this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df_act[0:39]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a few of these \"actives\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "mols = []\n",
    "smiles_top = df_short.head(5).smiles.to_list()\n",
    "print(smiles_top)\n",
    "for mysmiles in smiles_top :\n",
    "\n",
    "    mol = Chem.MolFromSmiles(mysmiles)\n",
    "    mols.append(mol)\n",
    "\n",
    "# mylegends = [ \"CID \" + str(x) for x in cids_top ]\n",
    "img = Draw.MolsToGridImage(mols, molsPerRow=2, subImgSize=(400,400))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Similarity Search against PubChem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's perform similarity search against PubChem using each known active compound as a query.  There are a few things to mention in this step:\n",
    "\n",
    "- The isomeric SMILES string is available for each query compound. This string will be used to specify the input structure, so HTTP POST should be used.  (Please review lecture03a-structure-inputs.ipynb)\n",
    "\n",
    "- During PubChem's similarity search, molecular similarity is evaluated using the **PubChem fingerprints** and **Tanimoto** coefficient.  By default, similarity search will return compounds with Tanimoter scores of **0.9 or higher**.  While we will use the default threshold in this practice, it is noteworthy that it is adjustable.  If you use a higher threshold (e.g., 0.99), you will get a fewer hits, which are too similar to the query compounds.  If you use a lower threshold (e.g., 0.88), you will get more hits, but they will include more false positives.\n",
    "\n",
    "- PubChem's similarity search does **not** return the similarity scores between the query and hit compounds.  Only the hit compound list is returned, which makes it difficult to rank the hit compounds for compound selection.  To address this issue, for each hit compound, we compute **the number of query compounds that returned that compound as a hit.**  \\[Because we are using multiple query compounds for similarity search, it is possible for different query compounds to return the same compound as a hit.  That is, the hit compound may be similar to multiple query compounds.  The underlying assumption is that hit compounds returned multiple times from different queries are more likely to be active than those returned only once from a single query.\\]\n",
    "\n",
    "- Add \"time.sleep()\" to avoid overloading PubChem servers and getting blocked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_act = df_short.smiles.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "prolog = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug\"\n",
    "\n",
    "cids_hit = dict()\n",
    "\n",
    "for idx, mysmiles in enumerate(smiles_act) :\n",
    "    \n",
    "    mydata = { 'smiles' : mysmiles }\n",
    "    \n",
    "    url = prolog + \"/compound/fastsimilarity_2d/smiles/cids/txt\"\n",
    "    res = requests.post(url, data=mydata)\n",
    "\n",
    "    if ( res.status_code == 200 ) :\n",
    "        cids = res.text.split()\n",
    "        cids = [ int(x) for x in cids ]    # Convert CIDs from string to integer.\n",
    "    else :\n",
    "        print(\"Error at\", idx, \":\", df_short.loc[idx,'id'], mysmiles )\n",
    "        print(res.status_code)\n",
    "        print(res.content)\n",
    "    \n",
    "    for mycid in cids:\n",
    "        cids_hit[mycid] = cids_hit.get(mycid, 0) + 1\n",
    "    \n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cids_hit)    # Show the number of compounds returned from any query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code cells, the returned hits are stored in a dictionary, along with the number of times they are returned.  Let's print the top 10 compounds that are returned the most number of times from the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_freq = [ (v, k) for k, v in cids_hit.items() ]\n",
    "sorted_by_freq.sort(reverse=True)\n",
    "\n",
    "for v, k in enumerate(sorted_by_freq) :\n",
    "\n",
    "    if v == 10 : \n",
    "        break\n",
    "    \n",
    "    print(v, k) # Print (frequency, CID)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exclude the query compounds from the hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous step, we repeated similarity searches using multiple query molecules.  This may result in a query molecule being returned as a hit from similarity search using another query molecule.  Therefore, we want to check if the hit compound list has any query compounds and if any, we want to remove them.  Below, we search PubChem for compounds identical to the query molecules and remove them from the hit compound list.<p>\n",
    "Note that the identity_type parameter in the PUG-REST request is set to \"**same_connectivity**\", which will return compounds with the same connectivity with the query molecule (ignoring stereochemistry and isotope information).  The default for this parameter is \"same_stereo_isotope\", which returns compounds with the same stereochemistry AND isotope information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cids_query = dict()\n",
    "\n",
    "for idx, mysmiles in enumerate(smiles_act) :\n",
    "    \n",
    "    mydata = { 'smiles' : mysmiles }\n",
    "    url = prolog + \"/compound/fastidentity/smiles/cids/txt?identity_type=same_connectivity\"\n",
    "    res = requests.post(url, data=mydata)\n",
    "\n",
    "    if ( res.status_code == 200 ) :\n",
    "        cids = res.text.split()\n",
    "        cids = [ int(x) for x in cids]\n",
    "    else :\n",
    "        print(\"Error at\", idx, \":\", df_short.loc[idx,'id'], mysmiles )\n",
    "        print(res.status_code)\n",
    "        print(res.content)\n",
    "       \n",
    "    for mycid in cids:\n",
    "        cids_query[mycid] = cids_query.get(mycid, 0) + 1\n",
    "    \n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cids_query.keys())    # Show the number of CIDs that represent the query compounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remove the query compounds from the hit list (if they are found in the list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mycid in cids_query.keys() :\n",
    "    \n",
    "    cids_hit.pop(mycid, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cids_hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the top 10 compounds in the current hit list and compare them with the old ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_freq = [ (v, k) for k, v in cids_hit.items() ]\n",
    "sorted_by_freq.sort(reverse=True)\n",
    "\n",
    "for v, k in enumerate(sorted_by_freq) :\n",
    "    \n",
    "    if v == 10 : \n",
    "        break\n",
    "    \n",
    "    print(v, k)    # Print (frequency, CID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filtering out non-drug-like compounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, non-drug-like compounds are filtered out from the list.  To do that, four molecular properties are downloaded from PubChem and stored in CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100\n",
    "\n",
    "if ( len(cids_hit) % chunk_size == 0 ) :\n",
    "    num_chunks = len(cids_hit) // chunk_size \n",
    "else :\n",
    "    num_chunks = len(cids_hit) // chunk_size + 1\n",
    "\n",
    "cids_list = list(cids_hit.keys())\n",
    "    \n",
    "print(\"# Number of chunks:\", num_chunks )\n",
    "\n",
    "csv = \"\"   #sets a variable called csv to save the comma separated output\n",
    "\n",
    "for i in range(num_chunks) :\n",
    "    \n",
    "    print(i, end=\" \")\n",
    "    \n",
    "    idx1 = chunk_size * i\n",
    "    idx2 = chunk_size * (i + 1)\n",
    "\n",
    "    cids_str = \",\".join([ str(x) for x in cids_list[idx1:idx2] ]) # build pug input for chunks of data\n",
    "    url = prolog + \"/compound/cid/\" + cids_str + \"/property/HBondDonorCount,HBondAcceptorCount,MolecularWeight,XLogP,CanonicalSMILES,IsomericSMILES/csv\"\n",
    "    \n",
    "    res = requests.get(url)\n",
    "    \n",
    "    if ( i == 0 ) : # if this is the first request, store result in empty csv variable\n",
    "        csv = res.text \n",
    "    else :          # if this is a subsequent request, add the request to the csv variable adding a new line between chunks\n",
    "        csv = csv + \"\\n\".join(res.text.split()[1:]) + \"\\n\" \n",
    "      \n",
    "    time.sleep(0.2)\n",
    "\n",
    "#print(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloaded data (in CSV) are loaded into a pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "csv_file = StringIO(csv)\n",
    "\n",
    "df_raw = pd.read_csv(csv_file, sep=\",\")\n",
    "\n",
    "df_raw.shape    # Show the shape (dimesnion) of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head(5)    # Show the first 5 rows of the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some compounds do not have computed XLogP values (because XLogP algorithm cannot handle inorganic compounds, salts, and mixtures) and we want to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.isna().sum()    # Check if there are any NULL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_raw)    # Check the number of rows (which is equals to the number of CIDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, add the information contained in the **cids_hit** dictionary to this data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the cids_hit dictionary into a data frame.\n",
    "df_freq = pd.DataFrame( cids_hit.items(), columns=['CID','HitFreq'])\n",
    "df_freq.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-check if the data are loaded correctly\n",
    "# Compare the data with those from Cell [13]\n",
    "df_freq.sort_values(by=['HitFreq', 'CID'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data frame called \"df\" by joining the df and df_freq data frames\n",
    "df = df_raw.join(df_freq.set_index('CID'), on='CID')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['HitFreq', 'CID'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Excercise:* Find the mean values for HBondDonorCount, HBondAcceptorCount, MolecularWeight, and XLogP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember dataframes have builtin tools for summarizing their data\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now identify and remove those compounds that satisfy all criteria of Lipinski's rule of five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[ df['HBondDonorCount'] <= 5 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[ df['HBondAcceptorCount'] <= 10 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[ df['MolecularWeight'] <= 500 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[ df['XLogP'] < 5 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[ ( df['HBondDonorCount'] <= 5) &\n",
    "         ( df['HBondAcceptorCount'] <= 10 ) &\n",
    "         ( df['MolecularWeight'] <= 500 ) &\n",
    "         ( df['XLogP'] < 5 ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Draw the structures of the top 5 compounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the structure of the top 10 compounds in the hit list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cids_top = df.sort_values(by=['HitFreq', 'CID'], ascending=False).head(5).CID.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "mols = []\n",
    "\n",
    "for mycid in cids_top :\n",
    "    \n",
    "    mysmiles = df[ df.CID==mycid ].IsomericSMILES.item()\n",
    "    \n",
    "    mol = Chem.MolFromSmiles( mysmiles )\n",
    "    Chem.FindPotentialStereoBonds(mol)    # Identify potential stereo bonds!\n",
    "    mols.append(mol)\n",
    "\n",
    "mylegends = [ \"CID \" + str(x) for x in cids_top ]\n",
    "img = Draw.MolsToGridImage(mols, molsPerRow=2, subImgSize=(400,400), legends=mylegends)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important observation from these images is that the hit list contains multiple compounds with the same connectivity.  For example, CIDs 93077065 and 93077064 are stereoisomers of each other and CID 53013349 has the same connectivity as the two CIDs, but with its stereocenter being unspecified. When performing a screening with limited resources in the early stage of drug discovery, you may want to test as diverse molecules as possible, avoiding testing too similar structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, let's look into PubChem's canonical SMILES strings, which do not encode the stereochemisry and isotope information.  Chemicals with the same connectivity but with different stereochemistry/isotopes should have the same canonical SMILES.  In the next section, we select unique compounds in terms of canonical SMILES to reduce the number of compounds to screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exersises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the Lipinski rule of 5 apply the Congreve’s rule of 3 to this data. This rule is used for identifying lead compounds. The rule of 3 filter was devised by Astex for fragment libraries as an equivalent to the Lipinski rule of 5 filter for drug like libraries, and is described in Congreve et al., Drug Discov. Today. 8 (19): 876–7, (2003).\n",
    "\n",
    "The default parameters used here are:\n",
    "\n",
    "Molecular weight <= 300\n",
    "LogP <= 3\n",
    "H-bond donor <= 3\n",
    "H-bond acceptor count <= 3\n",
    "Rotatable bond count <= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molecular_informatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
