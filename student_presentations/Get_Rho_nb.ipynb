{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"14\">Collect R-L BCPs with corresponding regions and Rho values.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is designed to pull data from a computational chemistry output file and merge the desired data into an Excel file that shows the bond paths between ligand and enzyme atoms with its corresponding Rho value. The output will be an Excel file containing system information about the bond paths, critical points, the regions, and charge density (rho).\n",
    "\n",
    "The first code block defines the current working directory, which file is used as input, and the ligand within the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "file_path = os.path.join(current_directory, \"pyrr1_c1_sys1_SP_QTAIM.out\") # Modify file name\n",
    "ligand = 'pyrr1' # Modify this as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script uses xlsxwriter and openpyxl to modifies and adjust Excel file.\n",
    "\n",
    "In your terminal, install xlsxwriter with the following command:\n",
    "\n",
    "    pip install xlsxwriter\n",
    "\n",
    "and\n",
    "\n",
    "    pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =\"10\">Section 1: Collecting Bond path information.</font>\n",
    "\n",
    "This section collects the \"Bond Path\" information from the AMS output file, used as input here, and creates an Excel file containing all bond path numbers, critical point numbers, and atom numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The temp_file_path text file will temporarily hold data before writing it to the bond_paths_full Excel file.\n",
    "\n",
    "temp_file_path = os.path.join(current_directory, \"temp_file.txt\")\n",
    "excel_path = os.path.join(current_directory, \"bond_paths_full.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_found = False # By initiating this condition as false, the function below will turn it True if the condition is found\n",
    "section_content = [] # This is where data is stored if section_found = True\n",
    "\n",
    "with open(file_path, 'r') as file: # Opens the input file\n",
    "    for line in file:\n",
    "        # Start recording from the occurrence of '   1      2  '\n",
    "        if '   1      2' in line and not section_found: # If this pattern is found while section_found = False\n",
    "            section_found = True # This condition is now true and the function will start appending lines to section_content\n",
    "            section_content.append(line)\n",
    "            continue\n",
    "\n",
    "        if section_found: # When this is true, continue reading and appending\n",
    "            if '---' in line or 'ANOTHER_SECTION_TITLE' in line or line.strip() == '': \n",
    "                break\n",
    "            section_content.append(line)\n",
    "    \n",
    "    if not section_found: # Fail if pattern is not found\n",
    "        print(\"Pattern '   1      2' not found. Exiting.\")\n",
    "        raise ValueError(\"Required pattern not found in the file.\")\n",
    "\n",
    "with open(temp_file_path, 'w') as temp_file:\n",
    "    temp_file.writelines(section_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block imports the lines from temp_file_path into a dataframe for readability. If the function read or appended correctly, then the first five rows of the dataframe will be printed and look similar to this:\n",
    "\n",
    "    First 5 rows of the DataFrame:\n",
    "     2   360       1      3     1.454230     1.454787      19\n",
    "    0     3   480       1    124     1.046427     1.0...      \n",
    "    1     4   219       2    115     3.034049     3.1...      \n",
    "    2     5   220       2    117     3.218932     3.2...      \n",
    "    3     6   377       3      4     1.530883     1.5...      \n",
    "    4     7   221       3     11     1.519229     1.5...      \n",
    "\n",
    "    The data has been written to the file:  path/to/directory/tempfile.txt\n",
    "\n",
    "If this does not appear, then the function did not work correctly. To troubleshoot, check:\n",
    "* Is the input file correctly named at the top of the script?\n",
    "* Does the ligand variable match the input file?\n",
    "* Some multi-atom files don't start with '   1      2' in the bond path section . Check the input file to see the first bond path is 1 to 3 or another atom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the DataFrame:\n",
      "  1   582       1      2     1.810282     1.811319      21\n",
      "0     2   350       1     10     1.533579     1.5...      \n",
      "1     3   415       1    156     1.107736     1.1...      \n",
      "2     4   711       1    157     1.109333     1.1...      \n",
      "3     5   516       1    251     2.893704     3.0...      \n",
      "4     6   348       2      3     1.196800     1.1...      \n",
      "\n",
      "The data has been written to the file: c:\\Users\\jenbu\\Desktop\\5580\\new_get_rho\\temp_file.txt\n"
     ]
    }
   ],
   "source": [
    "temp_file_df = pd.read_csv(temp_file_path)\n",
    "\n",
    "print(\"First 5 rows of the DataFrame:\")\n",
    "print(temp_file_df.head())\n",
    "print()\n",
    "print(f\"The data has been written to the file: {temp_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same data set is read into a dataframe, given names for each column and using the column specifications for exact width. Then, the atoms numbers for Atom 1 and Atom 2 are appended to the dataframe, which is then copied to a second dataframe which contains only the first four arrays. The second dataframe is constrained to not allow an index reset; early drafts of this script had atoms above 100 reindexed to 0.\n",
    "\n",
    "xlsxwriter is called in to write the second dataframe to an Excel file and set column widths. In the last line, the temporary text file is deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom column widths from the input file; currently interested in arrays 0-3; other arrays are important later\n",
    "colspecs = [(0, 4), (5, 10), (11, 20), (21, 30), (40, 50), (50, 60), (60, 70)]\n",
    "\n",
    "df = pd.read_fwf(temp_file_path, colspecs=colspecs)\n",
    "\n",
    "df.columns = ['#BP', '#CP', 'Atom 1', 'Atom 2', 'Distance', 'BP Length', 'BP Steps']\n",
    "\n",
    "df['Atom 1'] = pd.to_numeric(df['Atom 1'], errors='coerce') # Ensures integers; returns NaN if a number isn't present\n",
    "df['Atom 2'] = pd.to_numeric(df['Atom 2'], errors='coerce')\n",
    "\n",
    "df_shortened = df.iloc[:, :4]\n",
    "\n",
    "# Prevent resetting the index to avoid any unintended re-indexing; this avoids atom 100 written as 0, 101 as 1, 102 as 2, ... \n",
    "df_shortened.reset_index(drop=True, inplace=True)\n",
    "\n",
    "with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:\n",
    "    df_shortened.to_excel(writer, index=False)\n",
    "\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "    worksheet.set_column('A:D', 15) \n",
    "\n",
    "os.remove(temp_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block shows the first five lines from the shortened dataframe and should look similar to this:\n",
    "\n",
    "    First 5 rows of the DataFrame:\n",
    "            #BP  #CP  Atom 1  Atom 2\n",
    "        0    2  350       1      10\n",
    "        1    3  415       1     156\n",
    "        2    4  711       1     157\n",
    "        3    5  516       1     251\n",
    "        4    6  348       2       3  \n",
    "\n",
    "    The data has been written to the file:  path/to/directory/bond_paths_full.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the DataFrame:\n",
      "   #BP  #CP  Atom 1  Atom 2\n",
      "0    2  350       1      10\n",
      "1    3  415       1     156\n",
      "2    4  711       1     157\n",
      "3    5  516       1     251\n",
      "4    6  348       2       3\n",
      "\n",
      "The data has been written to the file: c:\\Users\\jenbu\\Desktop\\5580\\new_get_rho\\bond_paths_full.xlsx\n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 rows of the DataFrame:\")\n",
    "print(df_shortened.head())\n",
    "print()\n",
    "print(f\"The data has been written to the file: {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"12\">Section 2: Collecting Geometry information.</font>\n",
    "\n",
    "In this block, the code reads the \"Geometry\" section of the input file and places all atom numbers and atom regions into a new Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, new variables are designated, both the temporary text file and new Excel file.\n",
    "\n",
    "temp_file_path2 = os.path.join(current_directory, \"temp_file2.txt\")\n",
    "geometries = os.path.join(current_directory, \"geometry.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_found2 = False # By initiating this condition as false, the function below will turn it True if the condition is found\n",
    "section_content2 = [] # This is where data is stored if section_found = True\n",
    "\n",
    "with open(file_path, 'r') as file2: # Opens the input file\n",
    "    for line2 in file2:\n",
    "        # Check if the line contains the first occurrence of '#BP'\n",
    "        if '  Index Symbol   x (angstrom)   y (angstrom)   z (angstrom)' in line2 and not section_found2: # If pattern found while section_found2 = False\n",
    "            section_found2 = True  # Start recording from this point\n",
    "            section_content2.append(line2)\n",
    "            continue\n",
    "\n",
    "        if section_found2: # Continue reading and appending\n",
    "            if '---' in line2 or 'ANOTHER_SECTION_TITLE' in line2 or line2.strip() == '':\n",
    "                break\n",
    "          \n",
    "            section_content2.append(line2)\n",
    "\n",
    "    if not section_found2: # Fail if pattern is not found\n",
    "        print(\"Pattern for geometries not found. Exiting.\")\n",
    "        raise ValueError(\"Required pattern not found in the file.\")\n",
    "\n",
    "with open(temp_file_path2, 'w') as temp_file2: # Second temporary file\n",
    "    temp_file2.writelines(section_content2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column widths for the second temporary file\n",
    "column_widths = [7, 7, 15, 15, 15, 33]  # Accounts for long region names\n",
    "\n",
    "df2 = pd.read_fwf(temp_file_path2, widths=column_widths) # Read the second temporary file into a new data frame using column widths\n",
    "\n",
    "df2.to_excel(geometries, index=False) # Write the df to the geometry.xlsx file\n",
    "\n",
    "df2_shortened = df2.iloc[:, [0, 5]]  # Read only arrays 0 and 5 from the geomtery file to a new dataframe; 0 is atom number, 5 is region name\n",
    "\n",
    "df2_shortened.to_excel(geometries, index=False) # Rewrite to the same geometry.xlsx\n",
    "\n",
    "os.remove('temp_file2.txt') # Delete the second temporary file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block shows the first five lines from the second shortened dataframe with Geometry data:\n",
    "\n",
    "    First 5 rows of the DataFrame:\n",
    "        Index             Unnamed: 5\n",
    "    0      1  region=cys170minusONH\n",
    "    1      2  region=cys170minusONH\n",
    "    2      3  region=cys170minusONH\n",
    "    3      4  region=cys170minusONH\n",
    "    4      5   region=thr107minusCO\n",
    "\n",
    "\n",
    "    The data has been written to the file:  path/to/directory/geometry.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the DataFrame:\n",
      "   Index             Unnamed: 5\n",
      "0      1  region=cys170minusONH\n",
      "1      2  region=cys170minusONH\n",
      "2      3  region=cys170minusONH\n",
      "3      4  region=cys170minusONH\n",
      "4      5   region=thr107minusCO\n",
      "\n",
      "The data has been written to the file: c:\\Users\\jenbu\\Desktop\\5580\\new_get_rho\\geometry.xlsx\n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 rows of the DataFrame:\")\n",
    "print(df2_shortened.head())\n",
    "print()\n",
    "print(f\"The data has been written to the file: {geometries}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"12\">Section 3: Collate Bond Path Data with Geometry Data</font>\n",
    "\n",
    "The \"Geometry\" file is read and merged into the \"Bond Path\" file, creating a third Excel that contains the entire system's atoms, regions, and bond path numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bond_paths and geometry Excel files are called in as variables and will be used as input for the next function\n",
    "\n",
    "bond_paths_file = os.path.join(current_directory, \"bond_paths_full.xlsx\")\n",
    "geometry_file = os.path.join(current_directory, \"geometry_shortened.xlsx\")\n",
    "\n",
    "# After the function joins the relevant data from bond_path and geometry, it will sve it to the following file\n",
    "output_file = os.path.join(current_directory, \"bond_path_with_geo_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will correlate the atom numbers in bond_path to the atom numbers in geometries.\n",
    "\n",
    "def merge_bond_paths_with_regions(bond_paths_file, geometry_file, output_file): # input, input, output\n",
    "    bond_paths = pd.read_excel(excel_path) # input\n",
    "    geometry = pd.read_excel(geometries) # input\n",
    "    \n",
    "    # Creates column names for the geometry data; bond_path has headers, so to merge them, geometry nust have columns also\n",
    "    geometry.columns = ['Atom ID', 'Region']\n",
    "    \n",
    "    # In the bond_paths dataframe, create a column to the left of the Atom 1 column and place the region name from the geometry file\n",
    "    bond_paths = bond_paths.merge(geometry, how='left', left_on='Atom 1', right_on='Atom ID') \n",
    "    bond_paths = bond_paths.rename(columns={'Region': 'Region Atom 1'}).drop('Atom ID', axis=1)\n",
    "    \n",
    "    # In the bond_paths dataframe, create a column to the left of the Atom 2 column and place the region name from the geometry file\n",
    "    bond_paths = bond_paths.merge(geometry, how='left', left_on='Atom 2', right_on='Atom ID')\n",
    "    bond_paths = bond_paths.rename(columns={'Region': 'Region Atom 2'}).drop('Atom ID', axis=1)\n",
    "    \n",
    "    bond_paths.to_excel(output_file, index=False) # Write the data to the output file\n",
    "\n",
    "merge_bond_paths_with_regions(bond_paths_file, geometry_file, output_file) # Run the above function\n",
    "\n",
    "output_df = pd.read_excel(output_file) # Write the output to the bond_path_with_geo_data Excel file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block shows the first five lines from the second shortened dataframe with Geometry data:\n",
    "\n",
    "      First 5 rows of the DataFrame:\n",
    "         #BP  #CP  Atom 1  Atom 2          Region Atom 1          Region Atom 2\n",
    "      0    2  350       1      10  region=cys170minusONH  region=cys170minusONH\n",
    "      1    3  415       1     156  region=cys170minusONH  region=cys170minusONH\n",
    "      2    4  711       1     157  region=cys170minusONH  region=cys170minusONH\n",
    "      3    5  516       1     251  region=cys170minusONH          region=val77R\n",
    "      4    6  348       2       3  region=cys170minusONH  region=cys170minusONH\n",
    "\n",
    "\n",
    "    The data has been written to the file:  path/to/directory/bond_path_with_geo_data.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the DataFrame:\n",
      "   #BP  #CP  Atom 1  Atom 2          Region Atom 1          Region Atom 2\n",
      "0    2  350       1      10  region=cys170minusONH  region=cys170minusONH\n",
      "1    3  415       1     156  region=cys170minusONH  region=cys170minusONH\n",
      "2    4  711       1     157  region=cys170minusONH  region=cys170minusONH\n",
      "3    5  516       1     251  region=cys170minusONH          region=val77R\n",
      "4    6  348       2       3  region=cys170minusONH  region=cys170minusONH\n",
      "\n",
      "The data has been written to the file: c:\\Users\\jenbu\\Desktop\\5580\\new_get_rho\\bond_path_with_geo_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 rows of the DataFrame:\")\n",
    "print(output_df.head())\n",
    "print()\n",
    "print(f\"The data has been written to the file: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"12\">Section 4: Read Bond Path-Geometry Data for Ligand.</font>\n",
    "\n",
    "This section uses the \"Bond Path with Geo Data\" Excel file, which contains the entire system's bond paths, critical points, atoms, and regions for the variable 'ligand'. This is assigned at the top of the script as pyrr3. The 5 & 6 columns of the file, which contain region information, are read and return only rows where 'ligand' appears once. This is appended to a file called \"Bond Path Filtered\". \n",
    "\n",
    "There is no fail for this section; if the input had a Bond Path section, then it has Rho values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the joined bond path-geometry file to a new dataframe\n",
    "bond_path = os.path.join(current_directory, \"bond_path_with_geo_data.xlsx\")\n",
    "bond_path_df = pd.read_excel(bond_path)\n",
    "\n",
    "# Output file containing only lines where ligand appears once\n",
    "output_file2 = os.path.join(current_directory, \"bond_paths_filtered.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read through the bond_path_df to read for instances of 'ligand'. If 'ligand' is present in the 4th column and not the 5th,\n",
    "# or in the 5th column and not the 4th, append that entire line of data to the filtered dataframe\n",
    "\n",
    "filtered_df = bond_path_df[((bond_path_df.iloc[:, 4].str.contains(ligand, na=False)) & \n",
    "                            (~bond_path_df.iloc[:, 5].str.contains(ligand, na=False))) | # Ligand in 4 and not in 5\n",
    "                           ((~bond_path_df.iloc[:, 4].str.contains(ligand, na=False)) & \n",
    "                            (bond_path_df.iloc[:, 5].str.contains(ligand, na=False)))] # Ligand in 5 and not in 4\n",
    "\n",
    "# Write the filtered dataframe to a new Excel file\n",
    "filtered_df.to_excel(os.path.join(current_directory, output_file2), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block shows the first five lines from the second shortened dataframe with Geometry data:\n",
    "\n",
    "    First 5 rows of the DataFrame:\n",
    "        #BP  #CP  Atom 1  Atom 2          Region Atom 1 Region Atom 2\n",
    "    5     7  539       2     102  region=cys170minusONH  region=pyrr1\n",
    "    29   31  543      12     240    region=ala26minusNH  region=pyrr1\n",
    "    32   34  393      14      76    region=ala26minusNH  region=pyrr1\n",
    "    33   35  391      14     183    region=ala26minusNH  region=pyrr1\n",
    "    46   48  425      21      34         region=gln28BB  region=pyrr1   \n",
    "\n",
    "    The data has been written to the file:  path/to/directory/bond_path_filtered.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the DataFrame:\n",
      "    #BP  #CP  Atom 1  Atom 2          Region Atom 1 Region Atom 2\n",
      "5     7  539       2     102  region=cys170minusONH  region=pyrr1\n",
      "29   31  543      12     240    region=ala26minusNH  region=pyrr1\n",
      "32   34  393      14      76    region=ala26minusNH  region=pyrr1\n",
      "33   35  391      14     183    region=ala26minusNH  region=pyrr1\n",
      "46   48  425      21      34         region=gln28BB  region=pyrr1\n",
      "\n",
      "The data has been written to the file: c:\\Users\\jenbu\\Desktop\\5580\\new_get_rho\\bond_paths_filtered.xlsx\n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 rows of the DataFrame:\")\n",
    "print(filtered_df.head())\n",
    "print()\n",
    "print(f\"The data has been written to the file: {output_file2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is now an Excel file, bond_paths_filtered, that contains the bond path for 1 ligand atom interacting with a non-ligand atom. This data is useful for determining which residues in the active site interact with the ligand, for creating cluster models appropriate for QM analyses.\n",
    "\n",
    "Of immediate interest is collecting the charge density values of each of the bond paths. The summed rho value collected in the next section is most useful to qualifying inhibitor binding (weak, moderate, excellent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =\"12\">Section 5: Collate Rho Data.</font>\n",
    "\n",
    "Using the \"Bond Paths Filtered\" file, the input file is read for rho values of bond paths which contain exactly one instance of 'ligand'. The rho values and data from \"Bond Paths Filtered\" are appended to \"Bond Paths Rho\", which now contains all the desired data: bond path numbers, critical point numbers, both regions, and rho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the filtered bond path data and put in a dataframe\n",
    "bond_path2 = os.path.join(current_directory, \"bond_paths_filtered.xlsx\")\n",
    "bond_path_df2 = pd.read_excel(bond_path2)\n",
    "\n",
    "# Output file for relevant bond path and charge density data\n",
    "bond_path_rho = os.path.join(current_directory, \"bond_paths_rho.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads the initial input file for the bond path number, identifies the corresponding rho values, and appends\n",
    "# it to the rho_pattern variabe in scientific notation.\n",
    "\n",
    "def extract_rho_value(bond_path_number, file_path): \n",
    "    bond_path_pattern = f'CP #\\\\s*{bond_path_number}'  # The pattern is 'CP', for critical point. All CPs are collected here\n",
    "    rho_pattern = r'Rho\\s*=\\s*([\\d.eE+-]+)'  # Regex to capture scientific notation\n",
    "    section_found = False\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if re.search(bond_path_pattern, line): # if 'CP' is found in this line, read the next line\n",
    "                section_found = True  \n",
    "                continue\n",
    "            \n",
    "            if section_found:\n",
    "                match = re.search(rho_pattern, line) # Read this line for the rho_pattern\n",
    "                if match: #if found, return the Rho value in scientific notation as a float\n",
    "                    return float(match.group(1))  \n",
    "    return None\n",
    "\n",
    "# Read the dataframe for 'CP' and and for each line present, run the extract_rho_value function. Place the rho value associated with that bond path\n",
    "# back into the dataframe in a new column titled 'Rho'\n",
    "bond_path_df2['Rho'] = bond_path_df2['#CP'].apply(lambda x: extract_rho_value(x, file_path))\n",
    "\n",
    "# Write the expanded dataframe to the bond_path_rho Excel file\n",
    "bond_path_df2.to_excel(os.path.join(current_directory, bond_path_rho), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call in xlsxwriter to adjust the columns so the full region name is visible\n",
    "with pd.ExcelWriter(os.path.join(current_directory, bond_path_rho), engine='xlsxwriter') as writer:\n",
    "    bond_path_df2.to_excel(writer, index=False)\n",
    "\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "    worksheet.set_column('E:E', 25)  \n",
    "    worksheet.set_column('F:F', 25) \n",
    "    worksheet.set_column('G:G', 20) \n",
    "\n",
    "    # Identify the last row with rho values\n",
    "    last_row = len(bond_path_df2) + 1  # +1 for the header row\n",
    "\n",
    "    # Then sum all the rho values and place it at the end, bolded\n",
    "    worksheet.write_formula(f'G{last_row + 1}', f'=SUM(G2:G{last_row})', \n",
    "                            workbook.add_format({'bold': True}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block shows the first five lines from the second shortened dataframe with Geometry data:\n",
    "\n",
    "    First 5 rows of the DataFrame:\n",
    "    #BP  #CP  Atom 1  Atom 2          Region Atom 1 Region Atom 2       Rho\n",
    "    0    7  539       2     102  region=cys170minusONH  region=pyrr1  0.013294\n",
    "    1   31  543      12     240    region=ala26minusNH  region=pyrr1  0.017597\n",
    "    2   34  393      14      76    region=ala26minusNH  region=pyrr1  0.010896\n",
    "    3   35  391      14     183    region=ala26minusNH  region=pyrr1  0.014879\n",
    "    4   48  425      21      34         region=gln28BB  region=pyrr1  0.005474\n",
    "\n",
    "    The data has been written to the file:  path/to/directory/bond_path_rho.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the DataFrame:\n",
      "   #BP  #CP  Atom 1  Atom 2          Region Atom 1 Region Atom 2       Rho\n",
      "0    7  539       2     102  region=cys170minusONH  region=pyrr1  0.013294\n",
      "1   31  543      12     240    region=ala26minusNH  region=pyrr1  0.017597\n",
      "2   34  393      14      76    region=ala26minusNH  region=pyrr1  0.010896\n",
      "3   35  391      14     183    region=ala26minusNH  region=pyrr1  0.014879\n",
      "4   48  425      21      34         region=gln28BB  region=pyrr1  0.005474\n",
      "\n",
      "The data has been written to the file: c:\\Users\\jenbu\\Desktop\\5580\\new_get_rho\\bond_paths_rho.xlsx\n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 rows of the DataFrame:\")\n",
    "print(bond_path_df2.head())\n",
    "print()\n",
    "print(f\"The data has been written to the file: {bond_path_rho}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open the bond_path_rho Excel file, run one of the following cells depending on your OS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mac\n",
    "os.system(f\"open {os.path.join(current_directory, bond_path_rho)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linux\n",
    "os.system(f\"xdg-open {os.path.join(current_directory, bond_path_rho)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "os.startfile(os.path.join(current_directory, bond_path_rho))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"12\">Section 6: Remove all unnecessary files. </font>\n",
    "\n",
    "For extended troubleshooting purposes, absolutely don't run following script block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: c:\\Users\\jenbu\\Desktop\\5580\\new_get_rho\\bond_path_with_geo_data.xlsx\n",
      "Removed: c:\\Users\\jenbu\\Desktop\\5580\\new_get_rho\\bond_paths_filtered.xlsx\n",
      "Removed: c:\\Users\\jenbu\\Desktop\\5580\\new_get_rho\\bond_paths_full.xlsx\n",
      "Removed: c:\\Users\\jenbu\\Desktop\\5580\\new_get_rho\\geometry.xlsx\n"
     ]
    }
   ],
   "source": [
    "def remove_files(filenames, directory): # Remove any given files in a given directory\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(directory, filename) # Join the path and file name(s)\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "            print(f\"Removed: {file_path}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\") # Error if a file is not found in the directory\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing {file_path}: {e}\") # Error if a file cannot be removed (ie, it's open)\n",
    "\n",
    "files_to_remove = [ # Names of all the Excel files made earlier in the script\n",
    "    \"bond_path_with_geo_data.xlsx\",\n",
    "    \"bond_paths_filtered.xlsx\",\n",
    "    \"bond_paths_full.xlsx\",\n",
    "    \"geometry.xlsx\"\n",
    "]\n",
    "\n",
    "remove_files(files_to_remove, current_directory) # Run the function in the current working directory and List the removed files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=12>Is this accurate?</font>\n",
    "\n",
    "How do I know this worked instead of the script collecting random lines and appending values? The Excel generated with this script was compared against two other Excels: one created by two individuals performing manual analyses and one created by hobbling the results of two bash scripts together. The values were the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=12>Future Work</font>\n",
    "\n",
    "Next steps will be to make the entire script a single function that can iterate over several AMS output files, and collate them into a single Excel file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molecular-informatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
