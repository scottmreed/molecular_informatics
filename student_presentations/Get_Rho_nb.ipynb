{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"14\">Collect R-L BCPs with corresponding regions and Rho values.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is designed to pull data from a computational chemistry output file and merge the desired data into an Excel file that shows the bond paths between ligand and enzyme atoms with its corresponding Rho value. The output will be an Excel file containing system information about the bond paths, critical points, the regions, and charge density (rho)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "file_path = os.path.join(current_directory, \"pyrr1_c1_sys1_SP_QTAIM.out\") # Modify file name\n",
    "ligand = 'pyrr1' # Modify this as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this script, which modifies and adjusts Excel files, the python environment needs xlsxwriter and openpyxl installed.\n",
    "\n",
    "In your terminal, install xlsxwriter with the following command:\n",
    "\n",
    "    pip install xlsxwriter\n",
    "\n",
    "and\n",
    "\n",
    "    pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =\"10\">Section 1: Collecting Bond path information.</font>\n",
    "\n",
    "This section collects the \"Bond Path\" information from the AMS output file, used as input here, and creates an Excel file containing all bond path numbers, critical point numbers, and atom numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the DataFrame:\n",
      "  1   582       1      2     1.810282     1.811319      21\n",
      "0     2   350       1     10     1.533579     1.5...      \n",
      "1     3   415       1    156     1.107736     1.1...      \n",
      "2     4   711       1    157     1.109333     1.1...      \n",
      "3     5   516       1    251     2.893704     3.0...      \n",
      "4     6   348       2      3     1.196800     1.1...      \n",
      "\n",
      "The data has been written to the file: c:\\Users\\Bellu\\OneDrive\\Desktop\\temp_file.txt\n"
     ]
    }
   ],
   "source": [
    "temp_file_path = os.path.join(current_directory, \"temp_file.txt\")\n",
    "excel_path = os.path.join(current_directory, \"bond_paths_full.xlsx\")\n",
    "\n",
    "\n",
    "section_found = False\n",
    "section_content = []\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Start recording from the occurrence of '   1      2  '\n",
    "        if '   1      2  ' in line and not section_found:\n",
    "            section_found = True\n",
    "            section_content.append(line)\n",
    "            continue\n",
    "\n",
    "        if section_found:\n",
    "            if '---' in line or 'ANOTHER_SECTION_TITLE' in line or line.strip() == '':\n",
    "                break\n",
    "            section_content.append(line)\n",
    "    \n",
    "    if not section_found:\n",
    "        print(\"Pattern '   1      2  ' not found. Exiting.\")\n",
    "        raise ValueError(\"Required pattern not found in the file.\")\n",
    "\n",
    "with open(temp_file_path, 'w') as temp_file:\n",
    "    temp_file.writelines(section_content)\n",
    "\n",
    "temp_file_df = pd.read_csv(temp_file_path)\n",
    "\n",
    "print(\"First 5 rows of the DataFrame:\")\n",
    "print(temp_file_df.head())\n",
    "print()\n",
    "print(f\"The data has been written to the file: {temp_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the DataFrame:\n",
      "   #BP  #CP  Atom 1  Atom 2\n",
      "0    2  350       1      10\n",
      "1    3  415       1     156\n",
      "2    4  711       1     157\n",
      "3    5  516       1     251\n",
      "4    6  348       2       3\n",
      "\n",
      "The data has been written to the file: c:\\Users\\Bellu\\OneDrive\\Desktop\\bond_paths_full.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define custom column widths from the input file; currently interested in arrays 0-3; other arrays are important later\n",
    "colspecs = [(0, 4), (5, 10), (11, 20), (21, 30), (40, 50), (50, 60), (60, 70)]\n",
    "\n",
    "df = pd.read_fwf(temp_file_path, colspecs=colspecs)\n",
    "\n",
    "df.columns = ['#BP', '#CP', 'Atom 1', 'Atom 2', 'Distance', 'BP Length', 'BP Steps']\n",
    "\n",
    "df['Atom 1'] = pd.to_numeric(df['Atom 1'], errors='coerce') # Ensures integers; returns NaN if a number isn't present\n",
    "df['Atom 2'] = pd.to_numeric(df['Atom 2'], errors='coerce')\n",
    "\n",
    "df_shortened = df.iloc[:, :4]\n",
    "\n",
    "# Prevent resetting the index to avoid any unintended re-indexing; this avoids atom 100 written as 0, 101 as 1, 102 as 2, ... \n",
    "df_shortened.reset_index(drop=True, inplace=True)\n",
    "\n",
    "with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:\n",
    "    df_shortened.to_excel(writer, index=False)\n",
    "\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "    worksheet.set_column('A:D', 15) \n",
    "\n",
    "os.remove(temp_file_path)\n",
    "\n",
    "print(\"First 5 rows of the DataFrame:\")\n",
    "print(df_shortened.head())\n",
    "print()\n",
    "print(f\"The data has been written to the file: {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"12\">Section 2: Collecting Geometry information.</font>\n",
    "\n",
    "In this block, the code reads the \"Geometry\" section of the input file and places all atom numbers and atom regions into a new Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the DataFrame:\n",
      "   ------                      -\n",
      "0       1  region=cys170minusONH\n",
      "1       2  region=cys170minusONH\n",
      "2       3  region=cys170minusONH\n",
      "3       4  region=cys170minusONH\n",
      "4       5   region=thr107minusCO\n",
      "\n",
      "The data has been written to the file: c:\\Users\\Bellu\\OneDrive\\Desktop\\geometry.xlsx\n"
     ]
    }
   ],
   "source": [
    "temp_file_path2 = os.path.join(current_directory, \"temp_file2.txt\")\n",
    "geometries = os.path.join(current_directory, \"geometry.xlsx\")\n",
    "\n",
    "section_found2 = False\n",
    "section_content2 = []\n",
    "\n",
    "with open(file_path, 'r') as file2:\n",
    "    for line2 in file2:\n",
    "        # Check if the line contains the first occurrence of '#BP'\n",
    "        if '  Index Symbol   x (angstrom)   y (angstrom)   z (angstrom)' in line2 and not section_found2:\n",
    "            section_found2 = True  # Start recording from this point\n",
    "            section_content2.append(line2)\n",
    "            continue\n",
    "\n",
    "        if section_found2:\n",
    "            if '---' in line2 or 'ANOTHER_SECTION_TITLE' in line2 or line2.strip() == '':\n",
    "                break\n",
    "          \n",
    "            section_content2.append(line2)\n",
    "\n",
    "    if not section_found2:\n",
    "        print(\"Pattern for geometries not found. Exiting.\")\n",
    "        raise ValueError(\"Required pattern not found in the file.\")\n",
    "\n",
    "with open(temp_file_path2, 'w') as temp_file2: #local temp file\n",
    "    temp_file2.writelines(section_content2)\n",
    "\n",
    "column_widths = [7, 7, 15, 15, 15, 33]  # set widths for temporary file, accounts for long region names\n",
    "\n",
    "df2 = pd.read_fwf(temp_file_path2, widths=column_widths)\n",
    "\n",
    "df2.to_excel(geometries, index=False)\n",
    "\n",
    "df2_shortened = df2.iloc[:, [0, 5]]  # Index 0 is atom number, index 5 is region name\n",
    "\n",
    "df2_shortened.to_excel(geometries, index=False)\n",
    "\n",
    "os.remove('temp_file2.txt')\n",
    "\n",
    "print(\"First 5 rows of the DataFrame:\")\n",
    "print(df2_shortened.head())\n",
    "print()\n",
    "print(f\"The data has been written to the file: {geometries}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"12\">Section 3: Collate Bond Path Data with Geometry Data</font>\n",
    "\n",
    "The \"Geometry\" file is read and merged into the \"Bond Path\" file, creating a third Excel that contains the entire system's atoms, regions, and bond path numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the DataFrame:\n",
      "   #BP  #CP  Atom 1  Atom 2          Region Atom 1          Region Atom 2\n",
      "0    2  350       1      10  region=cys170minusONH  region=cys170minusONH\n",
      "1    3  415       1     156  region=cys170minusONH  region=cys170minusONH\n",
      "2    4  711       1     157  region=cys170minusONH  region=cys170minusONH\n",
      "3    5  516       1     251  region=cys170minusONH          region=val77R\n",
      "4    6  348       2       3  region=cys170minusONH  region=cys170minusONH\n",
      "\n",
      "The data has been written to the file: c:\\Users\\Bellu\\OneDrive\\Desktop\\bond_path_with_geo_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "bond_paths_file = os.path.join(current_directory, \"bond_paths_full.xlsx\")\n",
    "geometry_file = os.path.join(current_directory, \"geometry_shortened.xlsx\")\n",
    "output_file = os.path.join(current_directory, \"bond_path_with_geo_data.xlsx\")\n",
    "\n",
    "def merge_bond_paths_with_regions(bond_paths_file, geometry_file, output_file):\n",
    "    bond_paths = pd.read_excel(excel_path)\n",
    "    geometry = pd.read_excel(geometries)\n",
    "    \n",
    "    # Creates column names for the geometry data; because bond_path has headers, so to append them, geometry nust have columns also\n",
    "    geometry.columns = ['Atom ID', 'Region']\n",
    "    \n",
    "    bond_paths = bond_paths.merge(geometry, how='left', left_on='Atom 1', right_on='Atom ID') \n",
    "    bond_paths = bond_paths.rename(columns={'Region': 'Region Atom 1'}).drop('Atom ID', axis=1)\n",
    "    \n",
    "    bond_paths = bond_paths.merge(geometry, how='left', left_on='Atom 2', right_on='Atom ID')\n",
    "    bond_paths = bond_paths.rename(columns={'Region': 'Region Atom 2'}).drop('Atom ID', axis=1)\n",
    "    \n",
    "    bond_paths.to_excel(output_file, index=False)\n",
    "\n",
    "merge_bond_paths_with_regions(bond_paths_file, geometry_file, output_file)\n",
    "\n",
    "output_df = pd.read_excel(output_file)\n",
    "\n",
    "print(\"First 5 rows of the DataFrame:\")\n",
    "print(output_df.head())\n",
    "print()\n",
    "print(f\"The data has been written to the file: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"12\">Section 4: Read Bond Path-Geometry Data for Ligand.</font>\n",
    "\n",
    "This section uses the \"Bond Path with Geo Data\" Excel file, which contains the entire system's bond paths, critical points, atoms, and regions for the variable 'ligand'. This is assigned at the top of the script as pyrr3. The 5 & 6 columns of the file, which contain region information, are read and return only rows where 'ligand' appears once. This is appended to a file called \"Bond Path Filtered\". \n",
    "\n",
    "There is no fail for this section; if the input had a Bond Path section, then it has Rho values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the DataFrame:\n",
      "    #BP  #CP  Atom 1  Atom 2          Region Atom 1 Region Atom 2\n",
      "5     7  539       2     102  region=cys170minusONH  region=pyrr1\n",
      "29   31  543      12     240    region=ala26minusNH  region=pyrr1\n",
      "32   34  393      14      76    region=ala26minusNH  region=pyrr1\n",
      "33   35  391      14     183    region=ala26minusNH  region=pyrr1\n",
      "46   48  425      21      34         region=gln28BB  region=pyrr1\n",
      "\n",
      "The data has been written to the file: c:\\Users\\Bellu\\OneDrive\\Desktop\\bond_path_with_geo_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "bond_path = os.path.join(current_directory, \"bond_path_with_geo_data.xlsx\")\n",
    "bond_path_df = pd.read_excel(bond_path)\n",
    "\n",
    "filtered_df = bond_path_df[((bond_path_df.iloc[:, 4].str.contains(ligand, na=False)) & \n",
    "                            (~bond_path_df.iloc[:, 5].str.contains(ligand, na=False))) |\n",
    "                           ((~bond_path_df.iloc[:, 4].str.contains(ligand, na=False)) & \n",
    "                            (bond_path_df.iloc[:, 5].str.contains(ligand, na=False)))]\n",
    "\n",
    "filtered_df.to_excel(os.path.join(current_directory, \"bond_paths_filtered.xlsx\"), index=False)\n",
    "\n",
    "print(\"First 5 rows of the DataFrame:\")\n",
    "print(filtered_df.head())\n",
    "print()\n",
    "print(f\"The data has been written to the file: {bond_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =\"12\">Section 5: Collate Rho Data.</font>\n",
    "\n",
    "Using the \"Bond Paths Filtered\" file, the input file is read for rho values of bond paths which contain exactly one instance of 'ligand'. The rho values and data from \"Bond Paths Filtered\" are appended to \"Bond Paths Rho\", which now contains all the desired data: bond path numbers, critical point numbers, both regions, and rho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the DataFrame:\n",
      "   #BP  #CP  Atom 1  Atom 2          Region Atom 1 Region Atom 2       Rho\n",
      "0    7  539       2     102  region=cys170minusONH  region=pyrr1  0.013294\n",
      "1   31  543      12     240    region=ala26minusNH  region=pyrr1  0.017597\n",
      "2   34  393      14      76    region=ala26minusNH  region=pyrr1  0.010896\n",
      "3   35  391      14     183    region=ala26minusNH  region=pyrr1  0.014879\n",
      "4   48  425      21      34         region=gln28BB  region=pyrr1  0.005474\n",
      "\n",
      "The data has been written to the file: c:\\Users\\Bellu\\OneDrive\\Desktop\\bond_paths_filtered.xlsx\n"
     ]
    }
   ],
   "source": [
    "bond_path2 = os.path.join(current_directory, \"bond_paths_filtered.xlsx\")\n",
    "bond_path_df2 = pd.read_excel(bond_path2)\n",
    "\n",
    "def extract_rho_value(bond_path_number, file_path):\n",
    "    bond_path_pattern = f'CP #\\\\s*{bond_path_number}'  \n",
    "    rho_pattern = r'Rho\\s*=\\s*([\\d.eE+-]+)'  # Regex to capture scientific notation\n",
    "    section_found = False\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if re.search(bond_path_pattern, line):\n",
    "                section_found = True  \n",
    "                continue\n",
    "            \n",
    "            if section_found:\n",
    "                match = re.search(rho_pattern, line)\n",
    "                if match:\n",
    "                    return float(match.group(1))  # Return the Rho value in scientific notation as a float\n",
    "    return None\n",
    "\n",
    "bond_path_df2['Rho'] = bond_path_df2['#CP'].apply(lambda x: extract_rho_value(x, file_path))\n",
    "\n",
    "bond_path_df2.to_excel(os.path.join(current_directory, \"bond_paths_rho.xlsx\"), index=False)\n",
    "\n",
    "with pd.ExcelWriter(os.path.join(current_directory, \"bond_paths_rho.xlsx\"), engine='xlsxwriter') as writer:\n",
    "    bond_path_df2.to_excel(writer, index=False)\n",
    "\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "    worksheet.set_column('E:E', 25)  \n",
    "    worksheet.set_column('F:F', 25) \n",
    "    worksheet.set_column('G:G', 20) \n",
    "\n",
    "    last_row = len(bond_path_df2) + 1  # +1 for the header row\n",
    "\n",
    "    worksheet.write_formula(f'G{last_row + 1}', f'=SUM(G2:G{last_row})', \n",
    "                            workbook.add_format({'bold': True}))\n",
    "    \n",
    "print(\"First 5 rows of the DataFrame:\")\n",
    "print(bond_path_df2.head())\n",
    "print()\n",
    "print(f\"The data has been written to the file: {bond_path2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run one of the following cells depending on your OS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mac\n",
    "os.system(f\"open {os.path.join(current_directory, 'bond_paths_rho.xlsx')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux\n",
    "os.system(f\"xdg-open {os.path.join(current_directory, 'bond_paths_rho.xlsx')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "os.startfile(os.path.join(current_directory, \"bond_paths_rho.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"12\">Section 6: Remove all unnecessary files. </font>\n",
    "\n",
    "For troubleshooting purposes, absolutely don't run following script block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: c:\\Users\\Bellu\\OneDrive\\Desktop\\bond_path_with_geo_data.xlsx\n",
      "Removed: c:\\Users\\Bellu\\OneDrive\\Desktop\\bond_paths_filtered.xlsx\n",
      "Removed: c:\\Users\\Bellu\\OneDrive\\Desktop\\bond_paths_full.xlsx\n",
      "Removed: c:\\Users\\Bellu\\OneDrive\\Desktop\\geometry.xlsx\n"
     ]
    }
   ],
   "source": [
    "def remove_files(filenames, directory):\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "            print(f\"Removed: {file_path}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing {file_path}: {e}\")\n",
    "\n",
    "files_to_remove = [\n",
    "    \"bond_path_with_geo_data.xlsx\",\n",
    "    \"bond_paths_filtered.xlsx\",\n",
    "    \"bond_paths_full.xlsx\",\n",
    "    \"geometry.xlsx\"\n",
    "]\n",
    "\n",
    "remove_files(files_to_remove, current_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=12>Is this accurate?</font>\n",
    "\n",
    "How do I know this worked instead of the script collecting random lines and appending values? The Excel generated with this script was compared against two other Excels: one created by two individuals performing manual analyses and one created by hobbling the results of two bash scripts together. The values were the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=12>Future Work</font>\n",
    "\n",
    "Next steps will be to make the entire script a single function that can iterate over several AMS output files, and collate them into a single Excel file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JenEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
